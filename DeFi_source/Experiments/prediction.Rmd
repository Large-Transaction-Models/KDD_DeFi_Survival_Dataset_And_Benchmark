```{r setup, include=FALSE}
# Required R package installation; RUN THIS BLOCK BEFORE ATTEMPTING TO KNIT THIS NOTEBOOK!!!
# This section  install packages if they are not already installed. 
# This block will not be shown in the knit file.
knitr::opts_chunk$set(echo = TRUE)
# Set the default CRAN repository
local({r <- getOption("repos")
       r["CRAN"] <- "http://cran.r-project.org" 
       options(repos=r)
})
if (!require("survival")) {
  install.packages("survival")
  library(survival)
}
if (!require("randomForestSRC")) {
  install.packages("randomForestSRC")
  library(randomForestSRC)
}
if (!require("ggplot2")) {
  install.packages("ggplot2")
  library(ggplot2)
}
if (!require("pec")) {
  install.packages("pec")
  library(pec)
}
if (!require("dplyr")) {
  install.packages("dplyr")
  library(dplyr)
}
if (!require("survivalmodels")) {
  install.packages("survivalmodels")
  library(survivalmodels)
}
if (!require("SurvMetrics")) {
  install.packages("SurvMetrics")
  library(SurvMetrics)
}
if (!require("reticulate")) {
  install.packages("reticulate")
  library(reticulate)
}
if(!require("Hmisc")){
  install.packages("Hmisc")
  library(Hmisc)
}
# Set default functions for dplyr so we don't accidentally call plyr functions instead
select <- dplyr::select
rename <- dplyr::rename
summarize <- dplyr::summarize
group_by <- dplyr::group_by
## Helper functions
not_all_na <- function(x) any(!is.na(x))
`%notin%` <- Negate(`%in%`)
# Load all survival data
source("../dataLoader.R")
```
# Creating a Survival Prediction Benchmark:

Our benchmark should run various survival prediction models on each survival dataset we have (i.e. each combination of index and outcome event should have its own set of results).

There are three main tasks we need to complete for this survival prediction benchmark:
  1. We need to formulate the prediction task so it actually makes sense and does not leak future information in the training data.
  2. We need to decide on which prediction methods we want to include in the benchmark. There are some standard survival models that should definitely be included in the evaluation, like Cox Proportional Hazards. We also want to test some deep learning methods like DeepSurv, which can be accessed using the survivalModels package.
  3. We need to evaluate the effectiveness of these models using standard survival evaluation metrics. We should calculate the Concordance Index (C-Index), Integrated Brier Scores (IBS), and any other relevant evaluation metrics.
  
  
## Example: Cox Proportional Hazards with Borrow-to-Repay:

### 1. Load the dataset, filter out the irrelevant features, and make sure appropriate features are cast as factors:
```{r}
# Filter one dataset from the overall survival data:
borrowToRepay <- allSurvivalData %>%
  filter(`Index Event` == "borrow",
         `Outcome Event` == "repay") %>%
  select(where(not_all_na)) # Select just columns that aren't all NA values, because some of the features from other index-outcome combinations aren't necessarily relevant for this choice.
# We also should convert relevant columns to factors:
borrowToRepay[] <- lapply(borrowToRepay, 
                          function(x) if(is.character(x)) as.factor(x) else x)
```

### 2. Formulate a Train-Test split:
  We cannot just use an 80/20 Train/Test split because the data has a temporal component to it. We need to smartly formulate a prediction experiment that prevents temporal data from leaking across train and test sets.

  For an example, we formulate the experiment as follows: 
  * The training set temporal cutoff will be chosen as the end of 2022. We need to recalculate some of the event times in light of this cutoff, because we need to pretend that the final observation time is also the end of 2022 and censor events appropriately.
  * For events that occur in 2023, we will take index events that occur in the first six months of the year, and just one index event per unique user.

```{r}
trainCutoffDate <- 1672549199 # This is the UNIX timestamp for December 31, 2022 23:59:59
                              # If you want to play around with the cutoff date, here's a website the converts dates into UNIX timestamps: https://www.unixtimestamp.com/
trainData <- borrowToRepay %>%
  filter(indexTime <= trainCutoffDate)
# Recalculate whether the trainData events are censored, using trainCutoffDate as the new final time:
trainData <- trainData %>%
  mutate(status = case_when(outcomeTime > trainCutoffDate ~ 0, # if the outcome was witnessed, but after the training cutoff, we need to mark this event as censored.
                            TRUE ~ status)) %>%
  mutate(timeDiff = case_when(is.na(outcomeTime) ~ trainCutoffDate - indexTime, # if no outcome was witnessed, timeDiff needs to be recalculated
                              outcomeTime > trainCutoffDate ~ trainCutoffDate - indexTime,
                              TRUE ~ timeDiff)) %>%
  mutate(outcomeTime = case_when(outcomeTime > trainCutoffDate ~ NA, # outcomes seen after the cutoff are no longer seen.
                                 TRUE ~ outcomeTime))
trainData.X <- trainData %>%
  select(-timeDiff, -status) # We will have to do some additional feature selection later, too
trainData.Y <- trainData %>%
  select(timeDiff, status)
# Now to create the test data:
testCutoffDate <- 1688183999 # June 30, 2023 23:59:59
testData <- borrowToRepay %>%
  filter(indexTime > trainCutoffDate & indexTime <= testCutoffDate) # Select events in the first six months of 2023
testData <- testData %>%
  group_by(user) %>%
  slice_head(n=1) %>%
  ungroup() # Take just one event per user in this time period
testData.X <- testData %>%
  select(-timeDiff, -status) # We will have to do some additional feature selection later, too
testData.Y <- testData %>%
  select(timeDiff, status)
```

### 3. Fit a Cox Proportional Hazards model to the data and evaluate it's concordance index:
```{r}
# Assuming your dataframes are named train.X, train.Y, test.X, test.Y
# Combine train.X and train.Y to form the full survival object for the training set
train_data <- cbind(trainData.X, trainData.Y)
# Fit the Cox proportional hazards model to the training data
cox_model <- coxph(Surv(trainData.Y$timeDiff, trainData.Y$status) ~ reserve + quarter + coinType + amountUSD + amount, data = trainData.X)
# Summarize the model to see the fitted coefficients and p-values
summary(cox_model)
# Predict risk scores (linear predictors) for the test data using the fitted model
test_risk_scores <- predict(cox_model, newdata = testData.X, type = "risk")
# Evaluate the model on the test set using the concordance index (C-index)
# The C-index measures how well the model discriminates between pairs of individuals
# Higher values of C-index (closer to 1) indicate better performance
test_concordance <- rcorr.cens(test_risk_scores, Surv(testData.Y$timeDiff, testData.Y$status))
# Output the concordance index (C-index)
cat("Concordance Index (C-index) on the test set: ", test_concordance["C Index"], "\n")
```

Another good evaluation method for survival prediction is the Integrated Brier Score. We try to compute that here, but fail because I (Aaron) don't know exactly how the package works and it seems like we need to be smart about how we calculate them so we don't run out of RAM.

Someone can try and fix this
```{r}
# Time points for Brier score evaluation
time_points <- c(seq(0, 200, by = 20),    # Early stage: 20 every days
                 seq(200, 800, by = 50),  # Middle stage: every 50 days
                 seq(800, 1200, by = 100)) # Late stage: every 100 days
# Use these time points in the pec() function
brier_model <- pec(
  object = list("Cox" = cox_model),
  data = train_data,
  formula = Surv(timeDiff, status) ~ reserve + quarter + coinType + amountUSD + amount,
  exact = TRUE,
  cens.model = "cox",
  times = time_points,  # Define the time points
  splitMethod = "none"
)
# Extract the Integrated Brier Score (IBS)
ibs_value <- crps(brier_model, times = NULL)
cat("Integrated Brier Score (IBS): ", ibs_value, "\n")
```